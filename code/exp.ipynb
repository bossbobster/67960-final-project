{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731d7ff5",
   "metadata": {},
   "source": [
    "# **MoE Experiments**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03f6e9",
   "metadata": {},
   "source": [
    "First we just want to import the `Transformer` class as well as all of our custom MoE modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f815a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborne as sns\n",
    "import time\n",
    "\n",
    "from transformer import Transformer\n",
    "from moes import RegularMoE, RandomMoE, OrthogonalMoE, HashMoE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cpu\" and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.mps.manual_seed(67960)\n",
    "if device.type == \"cuda\" or device.type == \"cpu\":\n",
    "    torch.manual_seed(67960)\n",
    "\n",
    "B = 64\n",
    "V = 256\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156862f",
   "metadata": {},
   "source": [
    "Next, we want to import our data and get it ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5efd0b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AG News dataset...\n",
      "Training BPE tokenizer with vocab_size=V...\n",
      "\n",
      "\n",
      "\n",
      "Vocab size: 256\n",
      "Train samples: 120000, Test samples: 7600\n",
      "\n",
      "*Data done loading*\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
    "import torch\n",
    "\n",
    "# load dataset\n",
    "print(\"Loading AG News dataset...\")\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "\n",
    "# Train a simple BPE tokenizer on AG News (vocab V)\n",
    "print(\"Training BPE tokenizer with vocab_size=V...\")\n",
    "tokenizer_obj = Tokenizer(models.BPE())\n",
    "tokenizer_obj.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "\n",
    "# Train on first 10k samples (fast: ~10 seconds)\n",
    "trainer = trainers.BpeTrainer(vocab_size=V, special_tokens=[\"<PAD>\", \"<UNK>\"])\n",
    "tokenizer_obj.train_from_iterator(\n",
    "    (train_data[i]['text'] for i in range(min(10000, len(train_data)))),\n",
    "    trainer=trainer\n",
    ")\n",
    "\n",
    "# Simple wrapper to match expected API\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, tok):\n",
    "        self.tok = tok\n",
    "        self.pad_token_id = 0\n",
    "        \n",
    "    def __call__(self, text, truncation=True, max_length=128, padding='max_length', return_tensors='pt'):\n",
    "        encoding = self.tok.encode(text)\n",
    "        tokens = encoding.ids[:max_length]\n",
    "        tokens = tokens + [self.pad_token_id] * (max_length - len(tokens))\n",
    "        return {'input_ids': torch.tensor([tokens])}\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return self.tok.decode(ids.tolist() if isinstance(ids, torch.Tensor) else ids)\n",
    "\n",
    "tokenizer = SimpleTokenizer(tokenizer_obj)\n",
    "vocab_size = tokenizer_obj.get_vocab_size()\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Train samples: {len(train_data)}, Test samples: {len(test_data)}\")\n",
    "\n",
    "# dataset class\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, max_len=128):\n",
    "        self.data = hf_dataset\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]['text']\n",
    "        encoding = tokenizer(text, max_length=self.max_len+1)\n",
    "        tokens = encoding['input_ids'].squeeze(0)\n",
    "        \n",
    "        x = tokens[:-1]\n",
    "        y = tokens[1:]\n",
    "        mask = (x != tokenizer.pad_token_id)\n",
    "        return x, y, mask\n",
    "\n",
    "# create dataloaders\n",
    "train_dataset = TextDataset(train_data, max_len=128)\n",
    "test_dataset = TextDataset(test_data, max_len=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=B, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=B, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"\\n*Data done loading*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e622b17",
   "metadata": {},
   "source": [
    "Before we do anything, we want to set up some constants and create our `Transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e452906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: 256\n",
      " H: 512\n",
      " N: 32\n",
      " K: 4\n",
      " V: 256\n",
      " n_heads: 16\n",
      " n_layers: 6\n",
      " max_seq_len: 128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# create models\u001b[39;00m\n\u001b[32m     13\u001b[39m moe_fns = [\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: RegularMoE(D, H, N, K),\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: RandomMoE(D, H, N, K),\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: OrthogonalMoE(D, H, N, K),\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: HashMoE(D, H, N, K)\n\u001b[32m     18\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m models = [\u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoe_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m)\u001b[49m.to(device) \u001b[38;5;28;01mfor\u001b[39;00m moe_fn \u001b[38;5;129;01min\u001b[39;00m moe_fns]\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# print number of parameters in each model\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/67960-final-project/code/transformer.py:109\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, V, D, n_heads, n_layers, moe_fn, max_seq_len)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    107\u001b[39m \u001b[38;5;28mself\u001b[39m.embed = nn.Embedding(V, D)\n\u001b[32m    108\u001b[39m \u001b[38;5;28mself\u001b[39m.blocks = nn.ModuleList([\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     TransformerBlock(D, n_heads, \u001b[43mmoe_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, max_seq_len) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers)\n\u001b[32m    110\u001b[39m ])\n\u001b[32m    111\u001b[39m \u001b[38;5;28mself\u001b[39m.norm = nn.LayerNorm(D)\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.unembed = nn.Linear(D, V, bias=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mD\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m H: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m N: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m K: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m V: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mV\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m n_heads: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m n_layers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m max_seq_len: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_seq_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# create models\u001b[39;00m\n\u001b[32m     13\u001b[39m moe_fns = [\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: RegularMoE(D, H, N, K),\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: RandomMoE(D, H, N, K),\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: OrthogonalMoE(D, H, N, K),\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mHashMoE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m ]\n\u001b[32m     19\u001b[39m models = [Transformer(V, D, n_heads, n_layers, moe_fn, max_seq_len).to(device) \u001b[38;5;28;01mfor\u001b[39;00m moe_fn \u001b[38;5;129;01min\u001b[39;00m moe_fns]\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# print number of parameters in each model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/67960-final-project/code/moes.py:177\u001b[39m, in \u001b[36mHashMoE.__init__\u001b[39m\u001b[34m(self, D, H, N, K)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, D, H, N, K):\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(D, H, N, K, \u001b[43mHashRouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/67960-final-project/code/moes.py:90\u001b[39m, in \u001b[36mHashRouter.__init__\u001b[39m\u001b[34m(self, D, N)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# random unit-norm hyperplanes\u001b[39;00m\n\u001b[32m     89\u001b[39m W_DN = torch.randn(D, N)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m W_DN = W_DN / \u001b[43mW_DN\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mself\u001b[39m.register_buffer(\u001b[33m'\u001b[39m\u001b[33mW_DN\u001b[39m\u001b[33m'\u001b[39m, W_DN)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/67960-final-project/.venv/lib/python3.13/site-packages/torch/_tensor.py:871\u001b[39m, in \u001b[36mTensor.norm\u001b[39m\u001b[34m(self, p, dim, keepdim, dtype)\u001b[39m\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    868\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    869\u001b[39m         Tensor.norm, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, p=p, dim=dim, keepdim=keepdim, dtype=dtype\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/67960-final-project/.venv/lib/python3.13/site-packages/torch/functional.py:1660\u001b[39m, in \u001b[36mnorm\u001b[39m\u001b[34m(input, p, dim, keepdim, out, dtype)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m   1648\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnorm\u001b[39m(  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   1649\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1655\u001b[39m     ):\n\u001b[32m   1656\u001b[39m         \u001b[38;5;66;03m# type: (Tensor, str, Optional[int], bool, Optional[Tensor], Optional[int]) -> Tensor\u001b[39;00m\n\u001b[32m   1657\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1660\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnorm\u001b[39m(  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   1661\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1662\u001b[39m     p: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[33m\"\u001b[39m\u001b[33mfro\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1663\u001b[39m     dim=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1664\u001b[39m     keepdim=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1665\u001b[39m     out=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1666\u001b[39m     dtype=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1667\u001b[39m ):\n\u001b[32m   1668\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Returns the matrix norm or vector norm of a given tensor.\u001b[39;00m\n\u001b[32m   1669\u001b[39m \n\u001b[32m   1670\u001b[39m \u001b[33;03m    .. warning::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1758\u001b[39m \u001b[33;03m        (tensor(3.7417), tensor(11.2250))\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1761\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "D = 64\n",
    "H = 128\n",
    "N = 32\n",
    "K = 4\n",
    "V = vocab_size\n",
    "n_heads = 16\n",
    "n_layers = 6\n",
    "max_seq_len = 128\n",
    "\n",
    "print(f\"D: {D}\\n H: {H}\\n N: {N}\\n K: {K}\\n V: {V}\\n n_heads: {n_heads}\\n n_layers: {n_layers}\\n max_seq_len: {max_seq_len}\")\n",
    "\n",
    "# create models\n",
    "moe_fns = [\n",
    "    lambda: RegularMoE(D, H, N, K),\n",
    "    lambda: RandomMoE(D, H, N, K),\n",
    "    lambda: OrthogonalMoE(D, H, N, K),\n",
    "    lambda: HashMoE(D, H, N, K)\n",
    "]\n",
    "models = [Transformer(V, D, n_heads, n_layers, moe_fn, max_seq_len).to(device) for moe_fn in moe_fns]\n",
    "\n",
    "# print number of parameters in each model\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1} ({moe_fns[i]().__class__.__name__}) has {sum(p.numel() for p in model.parameters())} parameters and {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96194c9",
   "metadata": {},
   "source": [
    "Now we can finally train all of our models separately and then compare their results to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec1b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 1/4: RegularMoE\n",
      "============================================================\n",
      "375 batches to process...\n",
      "Time taken for forward pass: 7.2649s\n",
      "Time taken for backward pass: 0.9723s\n",
      "Time taken for forward pass: 0.3094s\n",
      "Time taken for backward pass: 0.6344s\n",
      "Time taken for forward pass: 0.3407s\n",
      "Time taken for backward pass: 0.6386s\n",
      "Time taken for forward pass: 0.2962s\n",
      "Time taken for backward pass: 0.6698s\n",
      "Time taken for forward pass: 0.3304s\n",
      "Time taken for backward pass: 0.6450s\n",
      "Time taken for forward pass: 0.3027s\n",
      "Time taken for backward pass: 0.6710s\n",
      "Time taken for forward pass: 1.0091s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m start_time = time.time()\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m train_losses.append(train_loss)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, device)\u001b[39m\n\u001b[32m     19\u001b[39m tm1 = time.time()\n\u001b[32m     20\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m     23\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/67960-final-project/.venv/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/67960-final-project/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/67960-final-project/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, optimizer, device):\n",
    "    \"\"\"Train for one epoch, return average loss\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    print(f\"{len(loader)} batches to process...\")\n",
    "    \n",
    "    for x, y, mask in loader:\n",
    "        x, y, mask = x.to(device), y.to(device), mask.to(device)\n",
    "        \n",
    "        # tm1 = time.time()\n",
    "        logits = model(x, mask)  # [B, S, V]\n",
    "        # tm2 = time.time()\n",
    "        # print(f\"Time taken for forward pass: {tm2 - tm1:.4f}s\")\n",
    "        \n",
    "        loss = F.cross_entropy(logits.view(-1, V), y.view(-1), ignore_index=tokenizer.pad_token_id)\n",
    "        \n",
    "        # tm1 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # tm2 = time.time()\n",
    "        # print(f\"Time taken for backward pass: {tm2 - tm1:.4f}s\")\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        if num_batches % 100 == 0:\n",
    "            print(f\"Processed {num_batches} batches...\")\n",
    "    return total_loss / num_batches\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"Evaluate on dataset, return average loss\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for x, y, mask in loader:\n",
    "        x, y, mask = x.to(device), y.to(device), mask.to(device)\n",
    "        logits = model(x, mask)\n",
    "        loss = F.cross_entropy(logits.view(-1, V), y.view(-1), ignore_index=tokenizer.pad_token_id)\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "# Training config\n",
    "num_epochs = 3\n",
    "lr = 3e-4\n",
    "model_names = [models[i].moe_fn().__class__.__name__ for i in range(len(models))]\n",
    "\n",
    "# Train each model\n",
    "results = {}\n",
    "for i, (model, name) in enumerate(zip(models, model_names)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Model {i+1}/{len(models)}: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate\n",
    "        test_loss = evaluate(model, test_loader, device)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    results[name] = {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'final_train_loss': train_losses[-1],\n",
    "        'final_test_loss': test_losses[-1]\n",
    "    }\n",
    "    \n",
    "    # Move back to CPU to free memory\n",
    "    model = model.cpu()\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "for name, res in results.items():\n",
    "    print(f\"{name:20s} | Train: {res['final_train_loss']:.4f} | Test: {res['final_test_loss']:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for name, res in results.items():\n",
    "    ax1.plot(range(1, num_epochs+1), res['train_losses'], marker='o', label=name)\n",
    "    ax2.plot(range(1, num_epochs+1), res['test_losses'], marker='o', label=name)\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Test Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21f12a",
   "metadata": {},
   "source": [
    "Now that we have all our models trained, we can look at their expert distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9c882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (RegularMoE), Layer 1: tensor([-0.8180,  0.7570,  0.0380,  0.0430])\n",
      "Model 1 (RegularMoE), Layer 2: tensor([-0.1360,  0.7410, -0.5800,  0.5250])\n",
      "Model 2 (RandomMoE), Layer 1: tensor([ 0.4550,  0.5620,  0.2820, -0.6190])\n",
      "Model 2 (RandomMoE), Layer 2: tensor([-0.9870, -0.0050,  0.6010,  1.0100])\n",
      "Model 3 (OrthogonalMoE), Layer 1: tensor([ 0.3070,  0.6240, -0.1080, -0.6270])\n",
      "Model 3 (OrthogonalMoE), Layer 2: tensor([ 0.9750, -0.2420, -1.0910,  1.1250])\n",
      "Model 4 (HashMoE), Layer 1: tensor([ 0.9850,  0.5780, -0.7800, -0.7630])\n",
      "Model 4 (HashMoE), Layer 2: tensor([-1.0270,  0.0150, -0.0810,  1.1250])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    for j, blk in enumerate(model.blocks):\n",
    "        print(f\"Model {i+1} ({model.moe_fn().__class__.__name__}), Layer {j+1}: {blk.moe.biases_N}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28569dae",
   "metadata": {},
   "source": [
    "We can also try to see how well our model predicts the next token on a given test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test example 0:\n",
      "Text: Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul....\n",
      "\n",
      "============================================================\n",
      "PERPLEXITY RESULTS\n",
      "============================================================\n",
      "RegularMoE           | Loss: 6.1774 | Perplexity: 481.74\n",
      "RandomMoE            | Loss: 6.2247 | Perplexity: 505.08\n",
      "OrthogonalMoE        | Loss: 5.6794 | Perplexity: 292.77\n",
      "HashMoE              | Loss: 6.4310 | Perplexity: 620.80\n",
      "\n",
      "Lower perplexity = better prediction\n",
      "(Perplexity measures how 'surprised' the model is by the actual next token)\n"
     ]
    }
   ],
   "source": [
    "# Test perplexity on a single example\n",
    "test_idx = 0\n",
    "test_text = test_data[test_idx]['text']\n",
    "print(f\"Test example {test_idx}:\")\n",
    "print(f\"Text: {test_text[:200]}...\")\n",
    "print()\n",
    "\n",
    "# Tokenize\n",
    "encoding = tokenizer(test_text, truncation=True, max_length=129, \n",
    "                     padding='max_length', return_tensors='pt')\n",
    "tokens = encoding['input_ids'].squeeze(0)\n",
    "x = tokens[:-1].unsqueeze(0).to(device)  # [1, 128]\n",
    "y = tokens[1:].unsqueeze(0).to(device)   # [1, 128]\n",
    "mask = (x != tokenizer.pad_token_id)\n",
    "\n",
    "# Test each model\n",
    "print(\"=\"*60)\n",
    "print(\"PERPLEXITY RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(x, mask)  # [1, S, V]\n",
    "        loss = F.cross_entropy(logits.view(-1, V), y.view(-1), \n",
    "                               ignore_index=tokenizer.pad_token_id, reduction='mean')\n",
    "        perplexity = torch.exp(loss).item()\n",
    "    \n",
    "    print(f\"{name:20s} | Loss: {loss.item():.4f} | Perplexity: {perplexity:.2f}\")\n",
    "    model = model.cpu()\n",
    "\n",
    "print()\n",
    "print(\"Lower perplexity = better prediction\")\n",
    "print(\"(Perplexity measures how 'surprised' the model is by the actual next token)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
